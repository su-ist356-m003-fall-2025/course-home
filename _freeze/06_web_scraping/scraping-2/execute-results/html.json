{
  "hash": "f8cc7e519b2bb919ff650c4bdd8f9420",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: '2. More Scraping + actionability'\njupyter: python3\n---\n\n\n\n\nUsing locators to find elements on the page is a fundamental part of web scraping. In this notebook, we'll learn how to use Playwright to find elements on the page using different types of locators.\n\n\n::: {.callout-note}\nIn this tutorial we will be diving more into the use of CSS selectors to scrape elements from a website. Our focus here is on how to do this with Playwright in Python. Getting good at web-scraping involves more in-depth use of CSS selectors than what we cover here. A good tutorial on the various CSS selectors and how to use query them when web-scraping can be found here:\n\n[ScrapingBee: Using CSS Selectors for Web Scraping](https://www.scrapingbee.com/blog/using-css-selectors-for-web-scraping/)\n:::\n\n## Scraping HTML tables\n\nWe saw previously that it's easy to scrape HTML tables into a pandas dataframe using [pd.read_html](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html).\n\nPreviously, we provided `read_html` a URL. However, you can also give the `read_url` a page as read by Playwright. Here's an example:\n\n::: {#51fc12f5 .cell execution_count=1}\n``` {.python .cell-code}\n# pw-pdtable.py\n\nfrom io import StringIO\nfrom playwright.sync_api import Playwright, sync_playwright\nimport pandas as pd\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://su-ist356-m003-fall-2025.github.io/course-home/syllabus.html\")\n\n    # ---------------------\n    # use pandas read_html to parse the HTML\n    # get a list of all tables on the page\n    dfs = pd.read_html(StringIO(page.content()))\n\n    # print the first table\n    print(dfs[0])\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n## Scraping the next adjcent element\n\nSometimes you need to use one selector to **find** the element, but what we want is to scrape the **next** element right after the page.\n\nTo find the next adjacent sibling element, you use: `.query_selector('~ *')`.\n\nHere's an example of using this to select the first element in the Course Info section of the course syllabus (use the Inspect tool in your web browser to understand what's going on here):\n\n::: {#fc9ba800 .cell execution_count=2}\n``` {.python .cell-code}\n# pw-scrape_next_example.py\nfrom playwright.sync_api import Playwright, sync_playwright\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://su-ist356-m003-fall-2025.github.io/course-home/syllabus.html\")\n    \n    # ---------------------\n    # Let's get course info from the syllabus\n    info_details = page.query_selector(\"section#course-info > h2.anchored\")\n    # Note: we could have alternatively selected the entire course\n    # section, then pulled out the h2 element, like this:\n    #course_info = page.query_selector(\"section#course-info\")\n    #info_details = course_info.query_selector(\"h2.anchored\")\n    # But the first way is more direct, as we only need the h2 element.\n    print(info_details.inner_text())\n    next_element = info_details.query_selector('~ *')\n    print(next_element.inner_text())\n\n\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\nUsing the next selector is useful if the information you're trying to scrape doesn't have a unique identifier, but something preceeding it (like a section header) does. It's also useful if you're not sure if, or don't want to assume that, the website has a particular CSS selector for the information you want to retrieve.\n\n:::: {.callout-caution appearance=\"simple\" icon=\"false\"}\n### Code Challenge 2.1\n\nScrape all the course info from the course syllabus:\n\nhttps://su-ist356-m003-fall-2025.github.io/course-home/syllabus.html\n\nDon't assume any CSS identifier for the course info, just step through the section until you have retrieve it all.\n\n*Hint:* Running `query_selector('~ *')` on the last child element in a parent element (like a section) will return None.\n\n::: {.callout-caution collapse=\"true\" appearance=\"simple\" icon=\"false\"}\n#### Solution\n\n::: {#268ce67a .cell execution_count=3}\n``` {.python .cell-code}\nfrom playwright.sync_api import Playwright, sync_playwright\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://su-ist356-m003-fall-2025.github.io/course-home/syllabus.html\")\n    \n    # ---------------------\n    # Let's get course info from the syllabus\n    info_details = page.query_selector(\"section#course-info > h2.anchored\")\n    print(info_details.inner_text())\n    next_element = info_details.query_selector('~ *')\n    # The following while loop will continue until next_element is None. That\n    # will happen once we've retrieved all available info from the section.\n    while next_element:\n        print(next_element.inner_text())\n        next_element = next_element.query_selector('~ *')\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n:::\n::::\n\n\n## Downloading an Image\n\nYou can use playwright to download an image by getting the `src` attribute. \n\nHere's an example in which we download the Syracuse University logo from the university's website:\n\n*Note: the downloaded file is an SVG file.*\n\n::: {#e611ffdf .cell execution_count=4}\n``` {.python .cell-code}\n# pw-image_example.py\n\nfrom playwright.sync_api import Playwright, sync_playwright\nimport requests\n\ndef download_image(url): \n    filename = url.split(\"/\")[-1]\n    response = requests.get(url) \n    with open(filename, 'wb') as file: \n        file.write(response.content)\n    return filename\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    site = \"https://www.syracuse.edu/\"\n    page.goto(site)\n    # ---------------------\n    image = page.query_selector(\"a.site-header-logo-link > img\")\n    image_source = image.get_attribute(\"src\")\n    print(f\"Downloading: {image_source}\")\n    filename = download_image(image_source)\n    print(f\"Saved to: {filename}\")\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n## Playwright Codegen \n\nPlaywright has a codegen feature that can help you generate code to interact with a webpage. \n\n\n\n\n```{bash}\npython -m playwright codegen \n```\n\n\n\n\nFor example, using code gen, we can generate the code needed to search for IST 356 in the course catalog:\n\n::: {#0b02c55c .cell execution_count=5}\n``` {.python .cell-code}\n# pw-codegen_example.py\nimport re\nfrom playwright.sync_api import Playwright, sync_playwright, expect\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://coursecatalog.syracuse.edu/course-search/\")\n    page.get_by_role(\"textbox\", name=\"Keyword\").fill(\"IST 356\")\n    page.get_by_role(\"button\", name=\"SEARCH\").click()\n    page.get_by_role(\"link\", name=\"IST 356 Programming\").click()\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n:::: {.callout-caution appearance=\"simple\" icon=\"false\"}\n### Code Challenge 2.2\n\nUse the playwright codegen to extract the SU football schedule from https://cuse.com \n\nInput the year, output the schedule.\n\n\n::: {.callout-caution collapse=\"true\" appearance=\"simple\" icon=\"false\"}\n#### Solution\n\n::: {#3f648dbc .cell execution_count=6}\n``` {.python .cell-code}\nfrom playwright.sync_api import Playwright, sync_playwright, expect\nimport pandas as pd\nfrom time import sleep\nimport sys\n\ndef run(playwright: Playwright, year) -> str:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(f\"https://cuse.com/sports/football/schedule/{year}\")\n    page.wait_for_load_state(\"load\")\n    sleep(1)\n    page.get_by_role(\"tab\", name=\"Table View not selected\").click()\n    sleep(1)\n    dfs = pd.read_html(page.content())\n    \n    \n    # ---------------------\n    context.close()\n    browser.close()\n    return dfs[0].to_html()\n\n\nwith sync_playwright() as playwright:\n    html_table = run(playwright, year=2023)\n    print (html_table)\n```\n:::\n\n\n:::\n::::\n\n",
    "supporting": [
      "scraping-2_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}