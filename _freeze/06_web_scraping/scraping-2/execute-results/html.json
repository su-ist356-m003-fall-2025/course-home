{
  "hash": "6c7b95ba9f08298cb4787b71e4085546",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: '2. More Scraping + actionability'\njupyter: python3\n---\n\nUsing locators to find elements on the page is a fundamental part of web scraping. In this notebook, we'll learn how to use Playwright to find elements on the page using different types of locators.\n\n\n::: {.callout-note}\nIn this tutorial we will be diving more into the use of CSS selectors to scrape elements from a website. Our focus here is on how to do this with Playwright in Python. Getting good at web-scraping involves more in-depth use of CSS selectors than what we cover here. A good tutorial on the various CSS selectors and how to use query them when web-scraping can be found here:\n\n[ScrapingBee: Using CSS Selectors for Web Scraping](https://www.scrapingbee.com/blog/using-css-selectors-for-web-scraping/)\n:::\n\n## Scraping HTML tables\n\nWe saw previously that it's easy to scrape HTML tables into a pandas dataframe using [pd.read_html](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html).\n\nPreviously, we provided `read_html` a URL. However, you can also give the `read_url` a page as read by Playwright. Here's an example:\n\n::: {#0316b76a .cell execution_count=1}\n``` {.python .cell-code}\n# pw-pdtable.py\n\nfrom io import StringIO\nfrom playwright.sync_api import Playwright, sync_playwright\nimport pandas as pd\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://su-ist356-m003-fall-2025.github.io/course-home/syllabus.html\")\n\n    # ---------------------\n    # use pandas read_html to parse the HTML\n    # get a list of all tables on the page\n    dfs = pd.read_html(StringIO(page.content()))\n\n    # print the first table\n    print(dfs[0])\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n## Scraping the next adjcent element\n\nSometimes you need to use one selector to **find** the element, but what we want is to scrape the **next** element right after the page.\n\nTo find the next adjacent sibling element, you use: `.query_selector('~ *')`.\n\nHere's an example of using this to select the first element in the Course Info section of the course syllabus (use the Inspect tool in your web browser to understand what's going on here):\n\n::: {#9665a7af .cell execution_count=2}\n``` {.python .cell-code}\n# pw-scrape_next_example.py\nfrom playwright.sync_api import Playwright, sync_playwright\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://su-ist356-m003-fall-2025.github.io/course-home/syllabus.html\")\n    \n    # ---------------------\n    # Let's get course info from the syllabus\n    info_details = page.query_selector(\"section#course-info > h2.anchored\")\n    # Note: we could have alternatively selected the entire course\n    # section, then pulled out the h2 element, like this:\n    #course_info = page.query_selector(\"section#course-info\")\n    #info_details = course_info.query_selector(\"h2.anchored\")\n    # But the first way is more direct, as we only need the h2 element.\n    print(info_details.inner_text())\n    next_element = info_details.query_selector('~ *')\n    print(next_element.inner_text())\n\n\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\nUsing the next selector is useful if the information you're trying to scrape doesn't have a unique identifier, but something preceeding it (like a section header) does. It's also useful if you're not sure if, or don't want to assume that, the website has a particular CSS selector for the information you want to retrieve.\n\n:::: {.callout-caution appearance=\"simple\" icon=\"false\"}\n### Code Challenge 2.1\n\nScrape all the course info from the course syllabus:\n\nhttps://su-ist356-m003-fall-2025.github.io/course-home/syllabus.html\n\nDon't assume any CSS identifier for the course info, just step through the section until you have retrieve it all.\n\n*Hint:* Running `query_selector('~ *')` on the last child element in a parent element (like a section) will return None.\n\n::: {.callout-caution collapse=\"true\" appearance=\"simple\" icon=\"false\"}\n#### Solution\n\n::: {#38aec6e4 .cell execution_count=3}\n``` {.python .cell-code}\nfrom playwright.sync_api import Playwright, sync_playwright\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://su-ist356-m003-fall-2025.github.io/course-home/syllabus.html\")\n    \n    # ---------------------\n    # Let's get course info from the syllabus\n    info_details = page.query_selector(\"section#course-info > h2.anchored\")\n    print(info_details.inner_text())\n    next_element = info_details.query_selector('~ *')\n    # The following while loop will continue until next_element is None. That\n    # will happen once we've retrieved all available info from the section.\n    while next_element:\n        print(next_element.inner_text())\n        next_element = next_element.query_selector('~ *')\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n:::\n::::\n\n\n## Downloading an Image\n\nYou can use playwright to download an image by getting the `src` attribute. \n\nHere's an example in which we download the Syracuse University logo from the university's website:\n\n*Note: the downloaded file is an SVG file.*\n\n::: {#cadfa7c6 .cell execution_count=4}\n``` {.python .cell-code}\n# pw-image_example.py\n\nfrom playwright.sync_api import Playwright, sync_playwright\nimport requests\n\ndef download_image(url): \n    filename = url.split(\"/\")[-1]\n    response = requests.get(url) \n    with open(filename, 'wb') as file: \n        file.write(response.content)\n    return filename\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    site = \"https://www.syracuse.edu/\"\n    page.goto(site)\n    # ---------------------\n    image = page.query_selector(\"a.site-header-logo-link > img\")\n    image_source = image.get_attribute(\"src\")\n    print(f\"Downloading: {image_source}\")\n    filename = download_image(image_source)\n    print(f\"Saved to: {filename}\")\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n## Playwright Codegen \n\nPlaywright has a codegen feature that can help you generate code to interact with a webpage. \n\n```{bash}\npython -m playwright codegen \n```\n\nFor example, using code gen, we can generate the code needed to search for IST 356 in the course catalog:\n\n::: {#f607a4e4 .cell execution_count=5}\n``` {.python .cell-code}\n# pw-codegen_example.py\nimport re\nfrom playwright.sync_api import Playwright, sync_playwright, expect\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://coursecatalog.syracuse.edu/course-search/\")\n    page.get_by_role(\"textbox\", name=\"Keyword\").fill(\"IST 356\")\n    page.get_by_role(\"button\", name=\"SEARCH\").click()\n    page.get_by_role(\"link\", name=\"IST 356 Programming\").click()\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\nOnce we have the code necessary to load the page, we can then use the Inspect tool in the open Chromium page to get whatever elements we want. For instance, inspecting the course description shows that it is in `<div class=\"section__content\">` which is a sub-element of `<div class=\"section section--description\">`. We can therefore retrieve the description with:\n\n::: {#3dc2ed28 .cell execution_count=6}\n``` {.python .cell-code}\n# pw-ist356description.py\nfrom playwright.sync_api import Playwright, sync_playwright\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://coursecatalog.syracuse.edu/course-search/\")\n    page.get_by_role(\"textbox\", name=\"Keyword\").click()\n    page.get_by_role(\"textbox\", name=\"Keyword\").fill(\"IST 356\")\n    page.get_by_role(\"button\", name=\"SEARCH\").click()\n    page.get_by_role(\"link\", name=\"IST 356 Programming\").click()\n    # ---------------------\n    descriptor = page.query_selector(\"div.section.section--description > div.section__content\")\n    course_description = descriptor.inner_text()\n    print(\"Course Description:\")\n    print(course_description)\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n## Pausing for elements to load\n\nIf you run the above code, you may find that it fails with:\n\n```{text}\n    course_description = descriptor.inner_text()\n                         ^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'inner_text'\n```\n\nThe reason for this is due to a mismatch in how long it takes Python to execute the lines locally versus how long it takes the website to serve up the requested content. In this case, the line `page.get_by_role(\"link\", name=\"IST 356 Programming\").click()` completes as soon as the click command is executed by Playwright. Python then goes on to execute the next line (the query selector). However, the time it takes for the webpage to update given the request -- i.e., for the course description to appear -- may take longer. The result is that when the `page.query_selector` line is run the course description has not actually appeared yet in the website, and so the query selector returns `None`.\n\nThis is a common problem when working with interactive websites like this. There are a couple ways to deal with this.\n\n### Using sleep to pause execution\n\nThe easiest (but kludgy) solution is to simply force your code to pause for a preset amount of time before trying to select anything off the site. You can do that with the [sleep](https://docs.python.org/3/library/time.html#time.sleep) command, which you need to import from the `time` module. Applying to our above example:\n\n::: {#5514214d .cell execution_count=7}\n``` {.python .cell-code}\n# pw-ist356description.py\nfrom playwright.sync_api import Playwright, sync_playwright\nfrom time import sleep\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://coursecatalog.syracuse.edu/course-search/\")\n    page.get_by_role(\"textbox\", name=\"Keyword\").click()\n    page.get_by_role(\"textbox\", name=\"Keyword\").fill(\"IST 356\")\n    page.get_by_role(\"button\", name=\"SEARCH\").click()\n    page.get_by_role(\"link\", name=\"IST 356 Programming\").click()\n    # ---------------------\n    # pause for a second to let the page fully load\n    sleep(1)\n    descriptor = page.query_selector(\"div.section.section--description > div.section__content\")\n    course_description = descriptor.inner_text()\n    print(\"Course Description:\")\n    print(course_description)\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\nThe `sleep(1)` line will cause the code to pause for 1 second. That (hopefully) is enough time for the website to finish loading, so that the subsequent lines will complete.\n\n::: {.callout-note}\nAs discussed below, using `sleep` to try to wait for an element to load is not a great solution. However, `sleep` is useful for debugging. As you've probably noticed, when your run a script, the browser that's loaded will disappear as soon as the code block is done executing. That can be very quick; too quick for you to see what it did. By sticking a `sleep` in your code for some longer period of time (say 60 seconds) you can get the browser to persist for awhile so you can see what was loaded, and inspect the page. This can help you debug any issues. Just remember to remove the `sleep` when you're done debugging!\n:::\n\n\n### Better: Waiting for the selector to appear\n\nUsing `sleep` works, but is not a great solution. First, you don't know how long it will take to load the element you need. This can be random, depending on your internet connection and the server's load at any given time. The time you hardcode may not always be long enough, or may be too long, in which case your program is wasting time.\n\nA better solution is to use Playwright's [wait_for_selector](https://playwright.dev/python/docs/api/class-page#page-wait-for-selector) method to wait for the desired element to appear. Here's how we can use that in our code above:\n\n::: {#5e45dfda .cell execution_count=8}\n``` {.python .cell-code}\n# pw-ist356description.py\nfrom playwright.sync_api import Playwright, sync_playwright\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://coursecatalog.syracuse.edu/course-search/\")\n    page.get_by_role(\"textbox\", name=\"Keyword\").click()\n    page.get_by_role(\"textbox\", name=\"Keyword\").fill(\"IST 356\")\n    page.get_by_role(\"button\", name=\"SEARCH\").click()\n    page.get_by_role(\"link\", name=\"IST 356 Programming\").click()\n    # ---------------------\n    element = \"div.section.section--description > div.section__content\"\n    # note: the timeout is in milliseconds\n    page.wait_for_selector(element, timeout=10000)\n    descriptor = page.query_selector(selector)\n    course_description = descriptor.inner_text()\n    print(\"Course Description:\")\n    print(course_description)\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\nThe `page.wait_for_selector(element, timeout=10000)` will cause the code to wait until the desired element appears on the page before continuing to the next line. This can be dangerous: if the element simply doesn't exist (say, you have a bug, or the website changed), your code could hang there. For this reason, it's good to provide a timeout. This will cause the code to raise an error if it takes longer for the element to appear than the specified timeout. Note that the timeout is in milliseconds; by specifying `timeout=10000` we've set the timeout to be 10 seconds.\n\n### Best: Using a locator\n\nIf you click on the documentation page for [wait_for_selector](https://playwright.dev/python/docs/api/class-page#page-wait-for-selector) you'll see that using `wait_for_selector` is discouraged. (There is a discussion on Stackoverflow [here](https://stackoverflow.com/questions/76093014/when-is-playwrights-waitforselector-necessary) about why.)\n\nThe best solution is instead to use [locators](https://playwright.dev/python/docs/locators). Locators are a more advanced way to location elements on a page. The code created by `codegen` made heavy use of them: all of those `page.get_by_role` lines are locators. You can do the same thing for the description. In fact, you can get `codegen` to give you the appropriate line of code by simply clicking on the \"Description\" header. Doing so in `codegen`, you'll see the line `page.get_by_role(\"heading\", name=\"Description\").click()` appear in the Playwright inspector.\n\nLocators have auto wait built into them, so you don't need to add any additional lines to get your code to wait for it. Our code therefore looks like:\n\n::: {#9ac257db .cell execution_count=9}\n``` {.python .cell-code}\n# pw-ist356description.py\nfrom playwright.sync_api import Playwright, sync_playwright\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://coursecatalog.syracuse.edu/course-search/\")\n    page.get_by_role(\"textbox\", name=\"Keyword\").fill(\"IST 356\")\n    page.get_by_role(\"button\", name=\"SEARCH\").click()\n    page.get_by_role(\"link\", name=\"IST 356 Programming\").click()\n    page.get_by_role(\"heading\", name=\"Description\").click()\n    # ---------------------\n    element = \"div.section.section--description > div.section__content\"\n    descriptor = page.query_selector(element)\n    course_description = descriptor.inner_text()\n    print(\"Course Description:\")\n    print(course_description)\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n:::: {.callout-caution appearance=\"simple\" icon=\"false\"}\n### Code Challenge 2.2\n\nUse the playwright codegen to extract the SU football schedule for 2023 from https://cuse.com. Output the table as a CSV.\n\n::: {.callout-caution collapse=\"true\" appearance=\"simple\" icon=\"false\"}\n#### Solution\n\n::: {#7848088a .cell execution_count=10}\n``` {.python .cell-code}\n# get_su_football_schedule.py\nfrom io import StringIO\nfrom playwright.sync_api import Playwright, sync_playwright, expect\nimport pandas as pd\n\ndef run(playwright: Playwright, year) -> str:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(f\"https://cuse.com/sports/football/schedule/{year}\")\n    page.get_by_role(\"tab\", name=\"Table View not selected\").click()\n    # clicking on the date column ensures that the table is loaded before we try to parse it\n    page.locator(\"[data-test-id=\\\"s-table__root\\\"]\").get_by_text(\"Date\").click()\n    # According to the Pandas docs, we now need to wrap content in StringIO\n    # before passing to read_html\n    dfs = pd.read_html(StringIO(page.content()))\n    context.close()\n    browser.close()\n    return dfs[0]\n\n\nwith sync_playwright() as playwright:\n    df = run(playwright, year=2023)\n    print(df.to_csv())\n```\n:::\n\n\n:::\n::::\n\n",
    "supporting": [
      "scraping-2_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}