{
  "hash": "da605caf12a4dc8afa49d5508157dd0e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: '1. Introduction to Web Scraping'\njupyter: python3\n---\n\n## The Anatomy of a Webpage: HTML, CSS and JavaScript\n\n- HTML (HyperText Markup Language) is the standard markup language for documents designed to be displayed in a web browser. It can be assisted by technologies such as Cascading Style Sheets (CSS) and scripting languages such as JavaScript.\n- CSS (Cascading Style Sheets) is a style sheet language used for describing the presentation of a document written in HTML or XML (including XML dialects such as SVG, MathML or XHTML).\n- JavaScript is a programming language that conforms to the ECMAScript specification. JavaScript is high-level, often just-in-time compiled, and multi-paradigm. It has curly-bracket syntax, dynamic typing, prototype-based object-orientation, and first-class functions.\n\n## Inspecting and Selecting\n\nYou don't need to be an HTML/CSS expert to scrape a webpage. \n\nYou just need to know how to inspect the webpage and select the elements you want to scrape.\n\nAs an illustration:\n\n1. Open Google Chrome\n2. Go to this site: https://www.imdb.com/chart/top/\n3. Right click on the title of the first movie.\n4. Click on \"Inspect\".\n5. Observe the `class=` attribute.\n5. Now right-click on the title of another movie.\n6. Click on \"Inspect\".\n7. Observe the `class=` attribute.\n\nAre the class attirbutes the same? (Ans: yes!) Then we should be able to scrape the titles easily!\n\n## Playwright\n\nTo programatically interact with websites (i.e., to web scrape) we will use [Playwright](https://playwright.dev/).\n\nPlaywright is a Node library to automate the Chromium, WebKit and Firefox browsers with a single API. It enables cross-browser web automation that is ever-green, capable, reliable and fast.\n\nYou can do everything a human can do in a web browser, just programmatically!\n\n::: {.callout-note}\n# Installing Playwright\n\nYou can install playwright using `pip`:\n\n1. Open a Terminal.\n2. Activate your `ist356` conda environment.\n3. Run `pip install playwright`\n:::\n\n\n### Installing the Chromium browser\n\nTo render and interact with web sites programattically playwright needs an open source browser. For that we will use [Chromium](https://en.wikipedia.org/wiki/Chromium_(web_browser)). Chromium is an open-source browser that was developed by Google. Chrome (which is closed source) and many other popular browsers (such as Microsoft Edge) are based on Chromium.\n\nWe can install Chromium using playwright. Open a new terminal, activate your `ist356` environment, then run:\n\n```{bash}\npython -m playwright  install chromium --with-deps\n```\n\nThis will install the chromium browser and all the dependencies needed to run it with playwright.\n\n### Making sure everything is working\n\nTo make sure its working, let's take a screenshot with playwright from the command line. In the terminal run:\n\n```{bash}\npython -m playwright screenshot https://www.google.com google.png\n```\n\nThis should create a file called `google.png` in your current directory. Open it; you should see a screenshot of Google's home page!\n\n## Playwright Boilerplate Code\n\nThe following code will open a browser, navigate to a page and get the contents of the page.\n\n::: {#b405971c .cell execution_count=1}\n``` {.python .cell-code}\n# pw-boilerplate.py\nfrom playwright.sync_api import Playwright, sync_playwright, expect\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://www.imdb.com/chart/top/\")\n    content = page.content()\n    print(content)\n\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\nTo run this, save it to a file on your computer (call it `pw-boilerplate.py`), then in your terminal run:\n\n```{bash}\npython pw-boilerplate.py\n```\n\nYou should briefly see a web page open then close. In your terminal, you'll see a bunch of text get written out. That is the content of the website (what you see when you use the Inspect tool in your browser). The content is what we'll be reading programatically.\n\n## Selectors\n\nTo scrape, you need to learn about selectors:\n\n| Example | Tag | Selector |\n| --- | --- | --- |\n| Class Selection | `<div class=\"something\">...</div>` | `\"div.something\"` |\n| Id Selection | `<table id=\"tid\">...</table>` | `\"table#tid\"` |\n| Tag Heirarchy Selection | `<h1><span>...</span></h1>` | `\"h1 > span\"` |\n| Multiple Tag Selection | `<h1>...</h1><h2>...</h2>` | `\"h1, h2\"` |\n| Next Selector | `<h1></h1><h2>...</h2>` | `\"~ *\"` |\n\n[https://www.w3schools.com/css/css_selectors.asp](https://www.w3schools.com/css/css_selectors.asp)\n\n\n## Getting the Select Element's tag name:\n\nThere's going to be times when you need to access the selected tag's name.\n\nThis is useful when building out the page structure. \n\nWe need to fall back to JavaScript to accomplish this. `evaluate()` executes a JavaScript function in the context of the selected element.\n\n::: {#f62a340a .cell execution_count=2}\n``` {.python .cell-code}\nselected = page.query_selector(\"h1\")\ntag = selected.evaluate(\"el => el.tagName\")\ntext = selected.inner_text()\n\nprint(tag, text)\n```\n:::\n\n\n## Example: Selecting the title \n\nThis example will select the \"title\" from the IMBD Page (the `<h1>` tag):\n\n::: {#691e1d06 .cell execution_count=3}\n``` {.python .cell-code}\n# pw-scrape_h1.py\n\nfrom playwright.sync_api import Playwright, sync_playwright, expect\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://www.imdb.com/chart/top/\")\n\n    # Let's scrape the heading off the page!\n    heading = page.query_selector(\"h1\")\n\n    # the tag name of the element\n    tag = heading.evaluate(\"el => el.tagName\")\n    print(tag)\n\n    # the contents of the element\n    print(heading.inner_text())\n    \n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\nAgain, to run this, save it to a file on your computer (call it `pw-scrape_h1.py`), then in your terminal run:\n\n```{bash}\npython pw-scrape_h1.py\n```\n\nYou should see Chromium briefly open at the website then close. In your terminal you should see the title of the page.\n\n:::: {.callout-caution appearance=\"simple\" icon=\"false\"}\n### Code Challenge 1.1\n\nScrape the title off the course webiste:  https://su-ist356-m003-fall-2025.github.io/course-home/\n\n*Hint:* Open your browser at the course website and inspect the title. You should see that is in a class element set to \"title\". This means you need to use the class selector to get the title.\n\n::: {.callout-caution collapse=\"true\" appearance=\"simple\" icon=\"false\"}\n#### Solution\n\n::: {#950001b5 .cell execution_count=4}\n``` {.python .cell-code}\nfrom playwright.sync_api import Playwright, sync_playwright, expect\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://su-ist356-m003-fall-2025.github.io/course-home/\")\n\n    # Let's scrape the heading off the page!\n    heading = page.query_selector(\"h1.title\")\n    print(heading.inner_text())\n    \n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\n:::\n::::\n\n\n## Scraping Multiple Elements\n\nTo scrape multiple elements, you can use the `query_selector_all` method.\n\nEvery matching element will be returned in a list.\n\nThis example gets all the movie titles from the IMDB page.\n\n::: {#fc451bc0 .cell execution_count=5}\n``` {.python .cell-code}\n# pw-selectall_example.py\nfrom playwright.sync_api import Playwright, sync_playwright, expect\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://www.imdb.com/chart/top/\")\n    \n    # select the title by selector\n    elements_on_page = page.query_selector_all(\"h3.ipc-title__text\")\n\n    # loop through the elements and print the title\n    for element in elements_on_page:\n        title = element.inner_text()\n        print(title)\n\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\nRun that:\n\n```{bash}\npython pw-selectall_example.py\n```\n\nYou should see the list of all the movies listed on the website in your terminal. However, there's also some extra stuff we don't want. This illustrates one of the challenges of web scraping: customizing your script to get exactly what you want. \n\n## Challenges of scraping\n\n1. Nothing is easy: Selecting exactly what you need from the page can be a challenge.\n2. Nothing stays the same: When a website changes its layout, your scraper will break.\n3. Nothing is consistent: Very little reuse from one page to the next.\n\n## Getting only what we want\n\nTo get only the titles, we need to be more specific in our selector. Here's a modified version of the code above:\n\n::: {#71e44575 .cell execution_count=6}\n``` {.python .cell-code}\n# pw-selectall_example2.py\nfrom playwright.sync_api import Playwright, sync_playwright, expect\n\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://www.imdb.com/chart/top/\")\n\n    # outer element that contains the list of 250 top movies\n    top_250_list = page.query_selector(\"ul.ipc-metadata-list\")\n\n    # same selector from there\n    elements_on_page = top_250_list.query_selector_all(\"h3.ipc-title__text\")\n    for element in elements_on_page:\n        title = element.inner_text()\n        print(title)\n\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright)\n```\n:::\n\n\nRunning the above, you should now get just the movie titles in your terminal.\n\n## Using playwright in a Jupyter notebook\n\nIn all the examples above we've run playwright in a Python script. If you tried running the same python in a Jupyter notebook cell, you'll get an Error, `Error: It looks like you are using Playwright Sync API inside the asyncio loop. Please use the Async API instead.`. This has to do with differences between asynchronous and synchronous, and how Jupyter works. Synchronous vs asynchronous programming is a subject unto itself (if you're interested, [this page](https://hamon.in/blog/conquering-timeouts-and-race-conditions-synchronous-vs-asynchronous-methods-in-playwright/) has a pretty good explainer), but long story short, to run playwright commands in a Jupyter notebook, you need to use their `async` API. You also need to prepend calls with the `await` command. For example, to load the IMDB top 250 page in a Jupyter notebook:\n\n::: {#67c75546 .cell execution_count=7}\n``` {.python .cell-code}\nfrom playwright.async_api import async_playwright\n\npw = await async_playwright().start()\nbrowser = await pw.chromium.launch(headless = False)\npage = await browser.new_page()\n\nawait page.goto(\"https://www.imdb.com/chart/top/\")\n```\n:::\n\n\nYou can now inspect various elements in your notebook with this. For example, to get the top 250 list from the page:\n\n::: {#6fbb1067 .cell execution_count=8}\n``` {.python .cell-code}\ntop_250_list = await page.query_selector(\"ul.ipc-metadata-list\")\n```\n:::\n\n\n:::: {.callout-caution appearance=\"simple\" icon=\"false\"}\n### Code Challenge 1.2\n\nCreate an outline!\n\nScrape the Sections H2 and H3 from this page:  https://ist256.com/fall2023/syllabus/\n\nPrint the titles, and detect the tag name so that you indent the H3 tags under the H2 tags.\n\n::: {.callout-caution collapse=\"true\" appearance=\"simple\" icon=\"false\"}\n#### Solution\n\n::: {#9c7e93f2 .cell execution_count=9}\n``` {.python .cell-code}\nfrom playwright.sync_api import Playwright, sync_playwright, expect\n\ndef run(playwright: Playwright) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://ist256.com/fall2023/syllabus/\")\n\n    # Let's scrape the heading off the page!\n    headings = page.query_selector_all(\"h2, h3\")\n    for heading in headings:\n        tag = heading.evaluate('el => el.tagName').lower()\n        text = heading.inner_text()\n        if tag == \"h2\":\n            print(text)\n        else:\n            print(f\"\\t{text}\")    \n\n    context.close()\n    browser.close()\n```\n:::\n\n\n:::\n::::\n\n",
    "supporting": [
      "scraping-1_files"
    ],
    "filters": [],
    "includes": {}
  }
}