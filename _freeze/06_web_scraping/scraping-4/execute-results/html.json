{
  "hash": "ff6124a28603fd8cb011db753edbee71",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: '4. Playwright + Argparse + Streamlit to create useful apps'\njupyter: python3\n---\n\n## Playwright + Argparse\n\nWe can create useful web scraping apps using `argparse` with `playwright`. \n\n### Example: an app to get the SU football schedule by year\n\nRecall Challenge 2.2 from the [second scraping tutorial](scraping-2.qmd). You were instructed to write a script that would get the SU football schedule for 2023. There, we hardcoded the year. However, we can create a much more useful script by using argparse to accept a year as input from the command line, like so:\n\n::: {#8ea37696 .cell execution_count=1}\n``` {.python .cell-code}\n# get_su_football_schedule.py\nfrom io import StringIO\nfrom playwright.sync_api import Playwright, sync_playwright, expect\nimport pandas as pd\nimport argparse\n\nparser = argparse.ArgumentParser(description=\"Retrieve the SU football schedule for the requested year.\")\nparser.add_argument(\"year\", type=int, help=\"The year to retrieve.\")\nparser.add_argument('-o', '--output', help=\"Write the output CSV to the given file. If none provided, will write to screen.\")\nargs = parser.parse_args()\n\ndef run(playwright: Playwright, year) -> str:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(f\"https://cuse.com/sports/football/schedule/{year}\")\n    page.get_by_role(\"tab\", name=\"Table View not selected\").click()\n    # clicking on the date column ensures that the table is loaded before we try to parse it\n    page.locator(\"[data-test-id=\\\"s-table__root\\\"]\").get_by_text(\"Date\").click()\n    # According to the Pandas docs, we now need to wrap content in StringIO\n    # before passing to read_html\n    dfs = pd.read_html(StringIO(page.content()))\n    context.close()\n    browser.close()\n    return dfs[0]\n\n\nwith sync_playwright() as playwright:\n    df = run(playwright, year=args.year)\n    if args.output is None:\n        print(df.to_csv())\n    else:\n        df.to_csv(args.output)\n```\n:::\n\n\n## Playwright + Streamlit\n\nDue to the multi-threaded nature of Streamlit, and playwright, there are some compatability on windows platforms. \n\n[https://discuss.streamlit.io/t/using-playwright-with-streamlit/28380](https://discuss.streamlit.io/t/using-playwright-with-streamlit/28380)\n\n\nTherefore, it is best to write the Playwright portion of the code as a stand-alone script, then call it from within the Streamlit app using `subprocess.run`.\n\nHere's an example in which we wrap the SU football script above and turn it into a Streamlit app:\n\n::: {#c6eb23ae .cell execution_count=2}\n``` {.python .cell-code}\n# st-get_su_football_schedule.py \nimport sys\nfrom subprocess import run\nimport streamlit as st\nimport pandas as pd\nfrom io import StringIO\n\n\ndef run_python_script(script_path : str, *args) -> str:\n    process = run([sys.executable, script_path]+list(args), text=True, capture_output=True)\n    output_text = process.stdout.strip()\n    return output_text\n\n\nst.title(\"Playwright with Streamlit\")\nst.caption(\"The strategy is to call the playwright code as a python script.\")\n\nyear = st.number_input(\"Enter a year\", min_value=2010, max_value=2025, value=2025)\nif year:\n    with st.spinner(\"Scraping...\"):\n        csv_content = run_python_script(\"get_su_football_schedule.py\", str(year))\n        # Note: we need to wrap CSV string content into a StringIO buffer\n        # in order for read_csv to understand it.\n        df = pd.read_csv(StringIO(csv_content))\n        st.dataframe(df)\n```\n:::\n\n\nSaving this to `st-get_su_football_schedule.py`, you can run it with:\n```{bash}\npython -m streamlit run st-get_su_football_schedule.py \n```\n\n:::: {.callout-caution appearance=\"simple\" icon=\"false\"}\n### Code Challenge 4.1\n\nWrite a script that will search the SU course catalog\n\nhttps://coursecatalog.syracuse.edu/course-search/\n\nfor a given course name and prints out its description. The course name should be provided on the command line.\n\n*Hint*: refer to the [scraping-2](scraping-2.qmd) tutorial to get started. Note that you\n\n::: {.callout-caution collapse=\"true\" appearance=\"simple\" icon=\"false\"}\n#### Solution\n\n::: {#3e23f69a .cell execution_count=3}\n``` {.python .cell-code}\nfrom playwright.sync_api import Playwright, sync_playwright\nimport argparse\n\nparser = argparse.ArgumentParser(description=\"Gets course information.\")\nparser.add_argument(\"course\", help=\"The course to retreive.\")\nargs = parser.parse_args()\n\ndef run(playwright: Playwright, course: str) -> None:\n    browser = playwright.chromium.launch(headless=False)\n    context = browser.new_context()\n    page = context.new_page()\n    page.goto(\"https://coursecatalog.syracuse.edu/course-search/\")\n    page.get_by_role(\"textbox\", name=\"Keyword\").fill(course)\n    page.get_by_role(\"button\", name=\"SEARCH\").click()\n    page.get_by_text(\"Found 1 course\").click()\n    page.locator(\"div\").filter(has_text=course).nth(3).click()\n    page.get_by_role(\"heading\", name=\"Description\").click()\n    # ---------------------\n    element = \"div.section.section--description > div.section__content\"\n    descriptor = page.query_selector(element)\n    course_description = descriptor.inner_text()\n    print(\"Course Description:\")\n    print(course_description)\n    # ---------------------\n    context.close()\n    browser.close()\n\n\nwith sync_playwright() as playwright:\n    run(playwright, args.course)\n```\n:::\n\n\n:::\n::::\n\n",
    "supporting": [
      "scraping-4_files"
    ],
    "filters": [],
    "includes": {}
  }
}